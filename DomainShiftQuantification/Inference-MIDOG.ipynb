{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done importing database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/aubrevillelocal/.local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/localhome/aubrevillelocal/SlideRunner/SlideRunner/dataAccess/database.py:2: UserWarning: Deprecated package. Please use the SlideRunner_dataAccess package, and not the SlideRunner main package for data access.\n",
      "  warnings.warn('Deprecated package. Please use the SlideRunner_dataAccess package, and not the SlideRunner main package for data access.')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "from SlideRunner_dataAccess.database import Database\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import openslide\n",
    "import time\n",
    "import pickle\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "import sys\n",
    "\n",
    "sys.path.append('lib/')\n",
    "from data_loader import *\n",
    "\n",
    "from lib.object_detection_helper import *\n",
    "from model.RetinaNetFocalLoss import RetinaNetFocalLoss\n",
    "from model.RetinaNet import RetinaNet\n",
    "import sys\n",
    "import threading\n",
    "from queue import Queue\n",
    "import queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading slides .. : 100%|██████████| 200/200 [00:00<00:00, 292.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on slides: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "size=512\n",
    "path = Path('./')\n",
    "\n",
    "database = Database()\n",
    "database.open('MIDOG.sqlite')\n",
    "slidedir = 'images_training'\n",
    "\n",
    "size = 512\n",
    "level = 0\n",
    "\n",
    "test_files = []\n",
    "\n",
    "\n",
    "test_slide_filenames = np.arange(41,51).tolist()+np.arange(91,101).tolist()+np.arange(141,151).tolist()\n",
    "\n",
    "files=list()\n",
    "train_files={'XR':[], 'S360':[],'CS2':[]}\n",
    "slidenames = list()\n",
    "getslides = \"\"\"SELECT uid, directory, filename FROM Slides\"\"\"\n",
    "for idx, (currslide, folder, filename) in enumerate(tqdm(database.execute(getslides).fetchall(), desc='Loading slides .. ')):\n",
    "        slidenames += [currslide]\n",
    "\n",
    "        database.loadIntoMemory(currslide)\n",
    "\n",
    "        slide_path = path / slidedir / filename\n",
    "        scont = SlideContainer(file=slide_path, level=level, width=size, height=size, y=[[], []], annotations=dict())\n",
    "        if ( (currslide in test_slide_filenames)):\n",
    "            test_files.append(scont)\n",
    "        elif (currslide<50):\n",
    "            train_files['XR'].append(scont)\n",
    "        elif (currslide<100):\n",
    "            train_files['S360'].append(scont)\n",
    "        elif (currslide<150):\n",
    "            train_files['CS2'].append(scont)\n",
    "        \n",
    "print('Running on slides:', slidenames)\n",
    "\n",
    "anchors = create_anchors(sizes=[(32,32)], ratios=[1], scales=[0.6, 0.7,0.8,0.9])\n",
    "\n",
    "detect_thresh = 0.3 \n",
    "nms_thresh = 0.4\n",
    "result_regression = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "jobQueue=Queue()\n",
    "outputQueue=Queue()\n",
    "\n",
    "def getPatchesFromQueue(jobQueue, outputQueue):\n",
    "    x,y=0,0\n",
    "    try:\n",
    "        while (True):\n",
    "            if (outputQueue.qsize()<100):\n",
    "                status, x,y, slide_container = jobQueue.get(timeout=60)\n",
    "                if (status==-1):\n",
    "                    return\n",
    "                outputQueue.put((x,y,slide_container.get_patch(x, y) / 255.))\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "    except queue.Empty:\n",
    "        print('One worker died.')\n",
    "        pass # Timeout happened, exit\n",
    "\n",
    "\n",
    "\n",
    "def getBatchFromQueue(batchsize=8):\n",
    "    images = np.zeros((batchsize,3, size,size))\n",
    "    x = np.zeros(batchsize)\n",
    "    y = np.zeros(batchsize)\n",
    "    try:\n",
    "        bs=0\n",
    "        for k in range(batchsize):\n",
    "            x[k],y[k],images_temp = outputQueue.get(timeout=5)\n",
    "            images[k] = images_temp.transpose((2,0,1))\n",
    "            bs+=1\n",
    "        return images,x,y\n",
    "    except queue.Empty:\n",
    "        return images[0:bs],x[0:bs],y[0:bs]\n",
    "\n",
    "\n",
    "def rescale_box(bboxes, size: Tensor):\n",
    "    bboxes[:, :2] = bboxes[:, :2] - bboxes[:, 2:] / 2\n",
    "    bboxes[:, :2] = (bboxes[:, :2] + 1) * size / 2\n",
    "    bboxes[:, 2:] = bboxes[:, 2:] * size / 2\n",
    "    bboxes = bboxes.long()\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "batchsize=8\n",
    "\n",
    "# Set up queued image retrieval\n",
    "jobs = []\n",
    "for i in range(1):\n",
    "    p = threading.Thread(target=getPatchesFromQueue, args=(jobQueue, outputQueue), daemon=True)\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, [40, 40, 40])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_files),[len(x) for x in train_files.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(files, mean, std, result_boxes={}):\n",
    "    with torch.no_grad():\n",
    "        for slide_container in tqdm(files):\n",
    "\n",
    "            size = 512\n",
    "\n",
    "            if '/'.join(str(slide_container.file).split('/')[-1:]) in result_boxes:\n",
    "                continue\n",
    "            result_boxes[str(slide_container.file).split(os.sep)[-1]] = []\n",
    "\n",
    "            n_Images=0\n",
    "            for x in range(0, slide_container.slide.level_dimensions[level][0] - 1 * size, int(0.9*size)):\n",
    "                for y in range(0, slide_container.slide.level_dimensions[level][1] - 1*  size, int(0.9*size)):\n",
    "                    jobQueue.put((0,x,y, slide_container))\n",
    "                    n_Images+=1\n",
    "\n",
    "\n",
    "            for kImage in range(int(np.ceil(n_Images/batchsize))):\n",
    "\n",
    "\n",
    "                    npBatch,xBatch,yBatch = getBatchFromQueue(batchsize=batchsize)\n",
    "                    imageBatch = torch.from_numpy(npBatch.astype(np.float32, copy=False)).cuda()\n",
    "\n",
    "                    patch = imageBatch\n",
    "\n",
    "                    for p in range(patch.shape[0]):\n",
    "                        patch[p] = transforms.Normalize(mean,std)(patch[p])\n",
    "\n",
    "                    class_pred_batch, bbox_pred_batch, _ = model(\n",
    "                        patch[:, :, :, :])\n",
    "\n",
    "                    for b in range(patch.shape[0]):\n",
    "                        x_real = xBatch[b]\n",
    "                        y_real = yBatch[b]\n",
    "\n",
    "                        for clas_pred, bbox_pred in zip(class_pred_batch[b][None,:,:], bbox_pred_batch[b][None,:,:],\n",
    "                                                                                ):\n",
    "                            modelOutput = process_output(clas_pred, bbox_pred, anchors, detect_thresh)\n",
    "                            bbox_pred, scores, preds = [modelOutput[x] for x in ['bbox_pred', 'scores', 'preds']]\n",
    "\n",
    "                            if bbox_pred is not None:\n",
    "                                to_keep = nms(bbox_pred, scores, nms_thresh)\n",
    "                                bbox_pred, preds, scores = bbox_pred[to_keep].cpu(), preds[to_keep].cpu(), scores[to_keep].cpu()\n",
    "\n",
    "                                t_sz = torch.Tensor([size, size])[None].float()\n",
    "\n",
    "                                bbox_pred = rescale_box(bbox_pred, t_sz)\n",
    "\n",
    "                                for box, pred, score in zip(bbox_pred, preds, scores):\n",
    "                                    y_box, x_box = box[:2]\n",
    "                                    h, w = box[2:4]\n",
    "\n",
    "                                    result_boxes[str(slide_container.file).split(os.sep)[-1]].append(np.array([x_box + x_real, y_box + y_real,\n",
    "                                                                                             x_box + x_real + w, y_box + y_real + h,\n",
    "                                                                                             pred, score]))\n",
    "    return result_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(fname):\n",
    "    state = torch.load(fname, map_location='cpu')     if defaults.device == torch.device('cpu')     else torch.load(fname)\n",
    "    model = state.pop('model').cuda()\n",
    "    mean = state['data']['normalize']['mean']\n",
    "    std = state['data']['normalize']['std']\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model = model.cuda(device)\n",
    "    return model, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [04:20<00:00,  6.44s/it]\n",
      "100%|██████████| 40/40 [04:17<00:00,  6.41s/it]\n",
      "100%|██████████| 40/40 [04:17<00:00,  6.43s/it]\n",
      "100%|██████████| 40/40 [04:17<00:00,  6.45s/it]\n",
      "100%|██████████| 40/40 [04:17<00:00,  6.45s/it]\n",
      "100%|██████████| 40/40 [04:07<00:00,  6.22s/it]\n",
      "100%|██████████| 40/40 [04:08<00:00,  6.26s/it]\n",
      "100%|██████████| 40/40 [04:08<00:00,  6.27s/it]\n",
      "100%|██████████| 40/40 [04:09<00:00,  6.28s/it]\n",
      "100%|██████████| 40/40 [04:09<00:00,  6.25s/it]\n",
      "100%|██████████| 40/40 [04:17<00:00,  6.43s/it]\n",
      "100%|██████████| 40/40 [04:17<00:00,  6.47s/it]\n",
      "100%|██████████| 40/40 [04:17<00:00,  6.46s/it]\n",
      "100%|██████████| 40/40 [04:17<00:00,  6.44s/it]\n",
      "100%|██████████| 40/40 [04:17<00:00,  6.47s/it]\n"
     ]
    }
   ],
   "source": [
    "result_boxes_train = {'S360':{},'CS2':{},'XR':{}}\n",
    "\n",
    "for scanner in ['S360','CS2','XR']:\n",
    "    for run in np.arange(1,6):\n",
    "        fname = f'RetinaNet-MIDOG-{scanner}-{run}.pth'\n",
    "        model,mean,std = load_model(fname)\n",
    "        result_boxes_train[scanner][run] = inference(train_files[scanner],mean,std,result_boxes={})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading slides .. : 100%|██████████| 73/73 [00:00<00:00, 160.37it/s]\n"
     ]
    }
   ],
   "source": [
    "database = Database()\n",
    "database.open('TUPAC_AL/TUPAC_alternativeLabels_training.sqlite')\n",
    "slidedir = 'TUPAC_AL/TUPACstitched/'\n",
    "\n",
    "size = 512\n",
    "level = 0\n",
    "\n",
    "train_files['TUPAC'] = []\n",
    "getslides = \"\"\"SELECT uid, directory, filename FROM Slides\"\"\"\n",
    "for idx, (currslide, folder, filename) in enumerate(tqdm(database.execute(getslides).fetchall(), desc='Loading slides .. ')):\n",
    "        slidenames += [currslide]\n",
    "\n",
    "        database.loadIntoMemory(currslide)\n",
    "\n",
    "        slide_path = path / slidedir / filename\n",
    "        scont = SlideContainer(file=slide_path, level=level, width=size, height=size, y=[[], []], annotations=dict())\n",
    "        train_files['TUPAC'].append(scont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [08:39<00:00,  1.96s/it]\n",
      "100%|██████████| 73/73 [08:50<00:00,  1.80s/it]\n",
      "100%|██████████| 73/73 [08:47<00:00,  1.85s/it]\n",
      "100%|██████████| 73/73 [08:46<00:00,  1.86s/it]\n",
      "100%|██████████| 73/73 [08:51<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "result_boxes_train['TUPAC']={}\n",
    "for run in np.arange(1,6):\n",
    "    fname = f'RetinaNet-TUPAC_AL-OrigSplit-512s-run{run}.pth'\n",
    "    model,mean,std = load_model(fname)\n",
    "    result_boxes_train['TUPAC'][run] = inference(train_files['TUPAC'],mean=mean,std=std,result_boxes={})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:17<00:00,  6.19s/it]\n",
      "100%|██████████| 30/30 [03:10<00:00,  6.14s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.15s/it]\n",
      "100%|██████████| 30/30 [03:10<00:00,  6.13s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.16s/it]\n"
     ]
    }
   ],
   "source": [
    "result_boxes = {'TUPAC':{},'S360':{},'CS2':{},'XR':{}}\n",
    "for run in np.arange(1,6):\n",
    "    fname = f'RetinaNet-TUPAC_AL-OrigSplit-512s-run{run}.pth'\n",
    "    model,mean,std = load_model(fname)\n",
    "    result_boxes['TUPAC'][run] = inference(test_files,mean=mean,std=std,result_boxes={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:10<00:00,  6.13s/it]\n",
      "100%|██████████| 30/30 [03:11<00:00,  6.14s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.12s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.13s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.14s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.14s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.15s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.14s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.16s/it]\n",
      "100%|██████████| 30/30 [03:10<00:00,  6.17s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.12s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.13s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.14s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.12s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.13s/it]\n"
     ]
    }
   ],
   "source": [
    "for scanner in ['S360','CS2','XR']:\n",
    "    for run in np.arange(1,6):\n",
    "        fname = f'RetinaNet-MIDOG-{scanner}-{run}.pth'\n",
    "        model,mean,std = load_model(fname)\n",
    "        result_boxes[scanner][run] = inference(test_files,mean,std,result_boxes={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.nms_WSI import nms as nms_WSI\n",
    "from lib.calculate_F1 import _F1_core\n",
    "\n",
    "def calculate_F1(DB, result_boxes=None, det_thres=0.5, hotclass=1,verbose=False):\n",
    "\n",
    "    if (result_boxes is None):\n",
    "        if resfile is None:\n",
    "            raise ValueError('At least one of resfile/result_boxes must be given')\n",
    "    \n",
    "    sTP, sFN, sFP = 0,0,0\n",
    "    F1dict = dict()\n",
    "    sP = 0\n",
    "    \n",
    "    result_boxes = nms_WSI(result_boxes, det_thres)\n",
    "    \n",
    "#    print('Calculating F1 for test set of %d files' % len(result_boxes),':',result_boxes.keys())\n",
    "    \n",
    "    slideids = []\n",
    "    \n",
    "    for resfile in result_boxes:\n",
    "        boxes = np.array(result_boxes[resfile])\n",
    "        \n",
    "\n",
    "        TP, FP, FN,F1 = 0,0,0,0\n",
    "        slide_id=DB.findSlideWithFilename(resfile,'')\n",
    "        slideids.append(str(slide_id))\n",
    "        DB.loadIntoMemory(slide_id)\n",
    "\n",
    "        annoList=[]\n",
    "        for annoI in DB.annotations:\n",
    "            anno = DB.annotations[annoI]\n",
    "            if anno.agreedClass==hotclass:\n",
    "                annoList.append([anno.x1,anno.y1])\n",
    "\n",
    "        centers_DB = np.array(annoList)\n",
    "\n",
    "        if boxes.shape[0]>0:\n",
    "            score = boxes[:,-1]\n",
    "            \n",
    "            F1,TP,FP,FN = _F1_core(centers_DB, boxes, score,det_thres)\n",
    "            if (centers_DB.shape[0] != TP+FN):\n",
    "                print(resfile,centers_DB.shape[0],TP+FN)\n",
    "        else: # no detections --> missed all\n",
    "            FN = centers_DB.shape[0] \n",
    "        \n",
    "        if (verbose):\n",
    "            print(f'{resfile}: F1:{F1}, TP:{TP}, FP:{FP}, FN:{FN}')\n",
    "\n",
    "\n",
    "        sTP+=TP\n",
    "        sFP+=FP\n",
    "        sP += centers_DB.shape[0]\n",
    "        sFN+=FN\n",
    "        F1dict[resfile]=F1\n",
    "        \n",
    "    sF1 = 2*sTP/(2*sTP + sFP + sFN)\n",
    "    #print('F1: ',sF1)\n",
    "    #print('Detections:', sFP+sTP)\n",
    "    #print('Precision: %.3f '%(sTP / (sTP+sFP)))\n",
    "    #print('Recall: %.3f' %(sTP / (sTP+sFN)))\n",
    "    \n",
    "    return sF1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_threshold(DB, result_boxes=None, hotclass=1, minthres=0.3):\n",
    "\n",
    "\n",
    "    sTP, sFN, sFP = 0,0,0\n",
    "    F1dict = dict()\n",
    "    \n",
    "    MIN_THR = minthres\n",
    "\n",
    "    result_boxes = nms_WSI(result_boxes, MIN_THR)\n",
    "    TPd, FPd, FNd, F1d = dict(), dict(), dict(), dict()\n",
    "    thresholds = np.arange(MIN_THR,0.99,0.01)\n",
    "    \n",
    "    print('Optimizing threshold for validation set of %d files: '%len(result_boxes.keys()))\n",
    "\n",
    "    for resfile in result_boxes:\n",
    "        boxes = np.array(result_boxes[resfile])\n",
    "\n",
    "        TP, FP, FN = 0,0,0\n",
    "        TPd[resfile] = list()\n",
    "        FPd[resfile] = list()\n",
    "        FNd[resfile] = list()\n",
    "        F1d[resfile] = list()\n",
    "\n",
    "        if (boxes.shape[0]>0):\n",
    "            score = boxes[:,-1]\n",
    "\n",
    "            DB.loadIntoMemory(DB.findSlideWithFilename(resfile,''))\n",
    "        \n",
    "            # perform NMS on detections\n",
    "\n",
    "            annoList=[]\n",
    "            for annoI in DB.annotations:\n",
    "                anno = DB.annotations[annoI]\n",
    "                if anno.agreedClass==hotclass:\n",
    "                    annoList.append([anno.x1,anno.y1])\n",
    "\n",
    "            centers_DB = np.array(annoList)\n",
    "\n",
    "\n",
    "\n",
    "            for det_thres in thresholds:\n",
    "                F1,TP,FP,FN = _F1_core(centers_DB, boxes, score,det_thres)\n",
    "                TPd[resfile] += [TP]\n",
    "                FPd[resfile] += [FP]\n",
    "                FNd[resfile] += [FN]\n",
    "                F1d[resfile] += [F1]\n",
    "        else:\n",
    "            for det_thres in thresholds:\n",
    "                TPd[resfile] += [0]\n",
    "                FPd[resfile] += [0]\n",
    "                FNd[resfile] += [0]\n",
    "                F1d[resfile] += [0]\n",
    "            F1 = 0\n",
    "            \n",
    "\n",
    "        F1dict[resfile]=F1\n",
    "\n",
    "    allTP = np.zeros(len(thresholds))\n",
    "    allFP = np.zeros(len(thresholds))\n",
    "    allFN = np.zeros(len(thresholds))\n",
    "    allF1 = np.zeros(len(thresholds))\n",
    "    allF1M = np.zeros(len(thresholds))\n",
    "\n",
    "\n",
    "\n",
    "    for k in range(len(thresholds)):\n",
    "        allTP[k] = np.sum([TPd[x][k] for x in result_boxes])\n",
    "        allFP[k] = np.sum([FPd[x][k] for x in result_boxes])\n",
    "        allFN[k] = np.sum([FNd[x][k] for x in result_boxes])\n",
    "        allF1[k] = 2*allTP[k] / (2*allTP[k] + allFP[k] + allFN[k])\n",
    "        allF1M[k] = np.mean([F1d[x][k] for x in result_boxes])\n",
    "\n",
    "    print('Best threshold: F1=', np.max(allF1), 'Threshold=',thresholds[np.argmax(allF1)])\n",
    "        \n",
    "    return thresholds[np.argmax(allF1)], allF1, thresholds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize threshold for TUPAC models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing threshold for validation set of 73 files: \n",
      "Best threshold: F1= 0.7329224447868515 Threshold= 0.6400000000000003\n",
      "Optimizing threshold for validation set of 73 files: \n",
      "Best threshold: F1= 0.7248391248391248 Threshold= 0.49000000000000016\n",
      "Optimizing threshold for validation set of 73 files: \n",
      "Best threshold: F1= 0.7286470143613001 Threshold= 0.4300000000000001\n",
      "Optimizing threshold for validation set of 73 files: \n",
      "Best threshold: F1= 0.7139622641509434 Threshold= 0.48000000000000015\n",
      "Optimizing threshold for validation set of 73 files: \n",
      "Best threshold: F1= 0.7168792934249264 Threshold= 0.5300000000000002\n"
     ]
    }
   ],
   "source": [
    "DBtupac = Database().open('TUPAC_AL/TUPAC_alternativeLabels_training.sqlite')\n",
    "thresholds = {'TUPAC':{},'XR':{},'CS2':{},'S360':{}}\n",
    "for run in np.arange(1,6):\n",
    "    thr = optimize_threshold(DBtupac, result_boxes_train['TUPAC'][run])\n",
    "    thresholds['TUPAC'][run]=thr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7003891050583657 Threshold= 0.4200000000000001\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7576530612244898 Threshold= 0.5500000000000003\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7428571428571429 Threshold= 0.5700000000000003\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7564766839378239 Threshold= 0.6200000000000003\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7107231920199502 Threshold= 0.5400000000000003\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7628607277289837 Threshold= 0.5500000000000003\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7865168539325843 Threshold= 0.6200000000000003\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7888748419721872 Threshold= 0.46000000000000013\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7894736842105263 Threshold= 0.49000000000000016\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7646356033452808 Threshold= 0.46000000000000013\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7906976744186046 Threshold= 0.5300000000000002\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7497879558948262 Threshold= 0.48000000000000015\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7628083491461101 Threshold= 0.5200000000000002\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7785467128027682 Threshold= 0.47000000000000014\n",
      "Optimizing threshold for validation set of 40 files: \n",
      "Best threshold: F1= 0.7775735294117647 Threshold= 0.5700000000000003\n"
     ]
    }
   ],
   "source": [
    "DB = Database().open('MIDOG.sqlite')\n",
    "#thresholds = {'TUPAC':{},'XR':{},'CS2':{},'S360':{}}\n",
    "for scanner in ['XR','S360','CS2']:\n",
    "    for run in np.arange(1,6):\n",
    "        thr = optimize_threshold(DB, result_boxes_train[scanner][run])\n",
    "        thresholds[scanner][run]=thr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = {'TUPAC': {}, 'XR': {}, 'S360':{}, 'CS2':{}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['TUPAC', 'S360', 'CS2', 'XR'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_boxes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = Database().open('MIDOG.sqlite')\n",
    "\n",
    "XR={}\n",
    "S360={}\n",
    "CS2={}\n",
    "F1\n",
    "for run in np.arange(1,6):\n",
    "    subset_XR = {f'{key:03d}.tiff': result_boxes['TUPAC'][run][f'{key:03d}.tiff'] for key in np.arange(41,51)}\n",
    "    subset_S360 = {f'{key:03d}.tiff': result_boxes['TUPAC'][run][f'{key:03d}.tiff'] for key in np.arange(91,101)}\n",
    "    subset_CS2 = {f'{key:03d}.tiff': result_boxes['TUPAC'][run][f'{key:03d}.tiff'] for key in np.arange(141,151)}\n",
    "    XR[run] = calculate_F1(database,subset_XR, float(thresholds['TUPAC'][run]))\n",
    "    S360[run] = calculate_F1(database,subset_S360, thresholds['TUPAC'][run])\n",
    "    CS2[run] = calculate_F1(database,subset_CS2, thresholds['TUPAC'][run])\n",
    "F1['TUPAC']['XR'] = XR\n",
    "F1['TUPAC']['CS2'] = CS2\n",
    "F1['TUPAC']['S360'] = S360\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5300000000000002"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds['TUPAC'][run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scanner in ['XR','S360','CS2']:\n",
    "    XR={}\n",
    "    S360={}\n",
    "    CS2={}\n",
    "    for run in np.arange(1,6):\n",
    "        subset_XR = {f'{key:03d}.tiff': result_boxes[scanner][run][f'{key:03d}.tiff'] for key in np.arange(41,51)}\n",
    "        subset_S360 = {f'{key:03d}.tiff': result_boxes[scanner][run][f'{key:03d}.tiff'] for key in np.arange(91,101)}\n",
    "        subset_CS2 = {f'{key:03d}.tiff': result_boxes[scanner][run][f'{key:03d}.tiff'] for key in np.arange(141,151)}\n",
    "        XR[run] = calculate_F1(database,subset_XR, thresholds[scanner][run])\n",
    "        S360[run] = calculate_F1(database,subset_S360, thresholds[scanner][run])\n",
    "        CS2[run] = calculate_F1(database,subset_CS2, thresholds[scanner][run])\n",
    "    F1[scanner]['XR'] = XR\n",
    "    F1[scanner]['CS2'] = CS2\n",
    "    F1[scanner]['S360'] = S360\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUPAC - XR -> 0.5530196039319556\n",
      "TUPAC - CS2 -> 0.6126767264719035\n",
      "TUPAC - S360 -> 0.40401938712468954\n",
      "CS2 - XR -> 0.38978205617708167\n",
      "CS2 - CS2 -> 0.7511055107990392\n",
      "CS2 - S360 -> 0.4331682525015938\n",
      "S360 - XR -> 0.4317875646331883\n",
      "S360 - CS2 -> 0.5735624727734937\n",
      "S360 - S360 -> 0.7206467988536656\n",
      "XR - XR -> 0.5777512932058386\n",
      "XR - CS2 -> 0.13761564427889653\n",
      "XR - S360 -> 0.19049689805992326\n"
     ]
    }
   ],
   "source": [
    "for k in ['TUPAC','CS2','S360','XR']:\n",
    "    for y in ['XR','CS2','S360']:\n",
    "        print(k,'-',y,'->',np.mean(list(F1[k][y].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUPAC - XR -> 0.03531442887465043\n",
      "TUPAC - CS2 -> 0.04987030933795765\n",
      "TUPAC - S360 -> 0.09017476055514971\n",
      "CS2 - XR -> 0.09657761102397405\n",
      "CS2 - CS2 -> 0.016233585938457865\n",
      "CS2 - S360 -> 0.16632850178046749\n",
      "S360 - XR -> 0.07742225497319043\n",
      "S360 - CS2 -> 0.08670102366506721\n",
      "S360 - S360 -> 0.025718316824473404\n",
      "XR - XR -> 0.025306216752117708\n",
      "XR - CS2 -> 0.13186975566551115\n",
      "XR - S360 -> 0.058260316773786854\n"
     ]
    }
   ],
   "source": [
    "for k in ['TUPAC','CS2','S360','XR']:\n",
    "    for y in ['XR','CS2','S360']:\n",
    "        print(k,'-',y,'->',np.std(list(F1[k][y].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUPAC & 0.55 $\\pm$ 0.04&0.61 $\\pm$ 0.05&0.40 $\\pm$ 0.09 \\\\\n",
      "XR & 0.58 $\\pm$ 0.03&0.14 $\\pm$ 0.13&0.19 $\\pm$ 0.06 \\\\\n",
      "CS2 & 0.39 $\\pm$ 0.10&0.75 $\\pm$ 0.02&0.43 $\\pm$ 0.17 \\\\\n",
      "S360 & 0.43 $\\pm$ 0.08&0.57 $\\pm$ 0.09&0.72 $\\pm$ 0.03 \\\\\n"
     ]
    }
   ],
   "source": [
    "for k in ['TUPAC','XR','CS2','S360']:\n",
    "    print(k,'& ',end='')\n",
    "    inf_scanner=[]\n",
    "    \n",
    "    for y in ['XR','CS2','S360']:\n",
    "        inf_scanner.append('%.2f $\\\\pm$ %.2f' % (np.mean(list(F1[k][y].values())), np.std(list(F1[k][y].values()))))\n",
    "    print('&'.join(inf_scanner),'\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(F1, open('F1_MIDOG.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0.74375, 0.6808510638297872, 0.7012987012987013, 0.7477744807121661, 0.7295597484276729])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One worker died.\n"
     ]
    }
   ],
   "source": [
    "F1[k][y].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
